{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', 55)\n",
    "pd.set_option('display.max_rows', 350)\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading cleaned ems dataframe pickle\n",
    "redo_pickle = False\n",
    "\n",
    "if redo_pickle == True:\n",
    "    with open('sf_ems_clean.pickle','wb') as f:\n",
    "        pickle.dump(df,f)\n",
    "        \n",
    "if redo_pickle == False:\n",
    "    with open('sf_ems_clean.pickle','rb') as f:\n",
    "        df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning GPS Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new columns for lat and long using cleaned location column\n",
    "\n",
    "# Cleaning location column\n",
    "df['Location'] = df['Location'].str.strip('()')\n",
    "\n",
    "# Create two lists for the loop results to be placed\n",
    "lat = []\n",
    "long = []\n",
    "\n",
    "# Looping through each row and extracting lat and long\n",
    "for row in df['Location']:\n",
    "    # Try to,\n",
    "    try:\n",
    "        # Split the row by comma and append\n",
    "        # everything before the comma to lat\n",
    "        lat.append((row.split(', ')[0]))\n",
    "        # Split the row by comma and append\n",
    "        # everything after the comma to long\n",
    "        long.append(row.split(', ')[1])\n",
    "    # But if you get an error\n",
    "    except:\n",
    "        # append a missing value to lat\n",
    "        lat.append(np.NaN)\n",
    "        # append a missing value to long\n",
    "        long.append(np.NaN)\n",
    "\n",
    "# Create two new columns from lat and lon\n",
    "df['latitude'] = lat\n",
    "df['longitude'] = long\n",
    "\n",
    "# Converting lat and long columns to floats\n",
    "df['latitude'] = pd.to_numeric(df['latitude'])\n",
    "df['longitude'] = pd.to_numeric(df['longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataframe in csv to observe gps coordinates in tableua\n",
    "df[df['Neighborhooods - Analysis Boundaries'] == 'None'].to_csv('no_label_ems_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA on Battalion Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B02     345964\n",
       "B03     344371\n",
       "B01     178161\n",
       "B04     172037\n",
       "B10     152409\n",
       "B08     144589\n",
       "B09     141605\n",
       "B06     132497\n",
       "B05     131701\n",
       "B07      87695\n",
       "B99       9357\n",
       "B100         1\n",
       "3E           1\n",
       "AMB          1\n",
       "Name: Battalion, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of ambulances called for each battalion from 2000 - 2019\n",
    "df[(df['Unit Type'] == 'MEDIC') | (df['Unit Type'] == 'PRIVATE')]['Battalion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005084251209934421"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of data that B99 accounts for\n",
    "# This is not actually a battalion so it must just be \n",
    "# a catch all for unlabeled calls\n",
    "9357/1840389\n",
    "\n",
    "# It's a relatively small percent but I would still \n",
    "# rather incorporate them into the model incase they\n",
    "# have some special meaning that I don't know about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading B99 dataframe in csv to observe gps coordinates in tableua\n",
    "# Goal is to \n",
    "df[(df['Battalion'] == 'B99') \n",
    "   & ((df['Unit Type'] == 'MEDIC') \n",
    "      | (df['Unit Type'] == 'PRIVATE'))].to_csv('b99_ems_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Number and Battalions\n",
    "* Checking to see if there is a there is only one battalion label for each call number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number call numbers per battalion\n",
    "battalion_overlap_call_number1 = df.groupby(['Incident Number','Battalion']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of battalions per call number \n",
    "battalion_overlap_call_number2 = df.groupby(['Incident Number','Battalion']).count().groupby('Incident Number').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the difference between number of call numbers per battalion and number of battalions per call number \n",
    "len(battalion_overlap_call_number2) - len(battalion_overlap_call_number1)\n",
    "\n",
    "# This is showing that there are no instances where a call \n",
    "# has several battalions that respond (or at least no times\n",
    "# that it was recorded)\n",
    "\n",
    "# This could mean that either dispatchers are making\n",
    "# a mistake in labeling or if multiple battalions respond to an emergency,\n",
    "# dispatchers just label the call as belonging to the battalion that responds first.\n",
    "# Either way, this indicates that battalion is not a reliable indicator of location\n",
    "# And so we must look for a better location metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Battalion DataFrames CSVs for Visualization in Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading B01 dataframe in csv to observe gps coordinates in tableua\n",
    "df[(df['Battalion'] == 'B01') \n",
    "   & ((df['Unit Type'] == 'MEDIC') \n",
    "      | (df['Unit Type'] == 'PRIVATE'))].to_csv('b01_ems_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading B02 dataframe in csv to observe gps coordinates in tableua\n",
    "df[(df['Battalion'] == 'B02') \n",
    "   & ((df['Unit Type'] == 'MEDIC') \n",
    "      | (df['Unit Type'] == 'PRIVATE'))].to_csv('b02_ems_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading B03 dataframe in csv to observe gps coordinates in tableua\n",
    "df[(df['Battalion'] == 'B03') \n",
    "   & ((df['Unit Type'] == 'MEDIC') \n",
    "      | (df['Unit Type'] == 'PRIVATE'))].to_csv('b03_ems_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading B04 dataframe in csv to observe gps coordinates in tableua\n",
    "df[(df['Battalion'] == 'B04') \n",
    "   & ((df['Unit Type'] == 'MEDIC') \n",
    "      | (df['Unit Type'] == 'PRIVATE'))].to_csv('b04_ems_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Mission dataframe in csv to observe gps coordinates in tableua\n",
    "df[(df['Neighborhooods - Analysis Boundaries'] == 'Mission') \n",
    "   & ((df['Unit Type'] == 'MEDIC') \n",
    "      | (df['Unit Type'] == 'PRIVATE'))].to_csv('mission_ems_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Inner Sunset dataframe in csv to observe gps coordinates in tableua\n",
    "df[(df['Neighborhooods - Analysis Boundaries'] == 'Inner Sunset') \n",
    "   & ((df['Unit Type'] == 'MEDIC') \n",
    "      | (df['Unit Type'] == 'PRIVATE'))].to_csv('inner sunset_ems_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning Neighborhoods into Battalions\n",
    "* Since neighborhoods is a very reliable indicator of location (as oppposed to the original battalion labels), I decided to manually bin each neighborhood into a battalion using batallion maps from online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe with only ambulances\n",
    "amb_df = df[(df['Unit Type'] == 'MEDIC') | (df['Unit Type'] == 'PRIVATE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to a csv for tableau visualization\n",
    "amb_df.to_csv('ambulance_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tenderloin                        278643\n",
       "South of Market                   202023\n",
       "Mission                           182014\n",
       "Financial District/South Beach    109525\n",
       "Bayview Hunters Point              97090\n",
       "Sunset/Parkside                    74061\n",
       "Western Addition                   67143\n",
       "Nob Hill                           56908\n",
       "Outer Richmond                     46505\n",
       "Castro/Upper Market                45578\n",
       "Hayes Valley                       45371\n",
       "West of Twin Peaks                 38561\n",
       "Excelsior                          37873\n",
       "North Beach                        36935\n",
       "Chinatown                          34559\n",
       "Bernal Heights                     33936\n",
       "Potrero Hill                       30389\n",
       "Marina                             30076\n",
       "Pacific Heights                    29964\n",
       "Outer Mission                      28363\n",
       "Haight Ashbury                     27671\n",
       "Oceanview/Merced/Ingleside         26361\n",
       "Inner Sunset                       25445\n",
       "Visitacion Valley                  24822\n",
       "Russian Hill                       24602\n",
       "Lakeshore                          24258\n",
       "Inner Richmond                     23220\n",
       "Lone Mountain/USF                  20105\n",
       "Mission Bay                        18767\n",
       "Portola                            18729\n",
       "Japantown                          17269\n",
       "Noe Valley                         16717\n",
       "Presidio Heights                   14229\n",
       "Treasure Island                    13121\n",
       "Golden Gate Park                   11006\n",
       "Twin Peaks                          9781\n",
       "Glen Park                           7767\n",
       "Presidio                            4890\n",
       "Seacliff                            2082\n",
       "None                                1673\n",
       "McLaren Park                        1384\n",
       "Lincoln Park                         973\n",
       "Name: Neighborhooods - Analysis Boundaries, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency of Neighborhoods in SF\n",
    "amb_df['Neighborhooods - Analysis Boundaries'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually created a dictionary with the corresponding \n",
    "# battalion for each neighborhood\n",
    "\n",
    "new_battalions = {'Outer Richmond':7,\n",
    "'Inner Richmond':7,\n",
    "'Seacliff':7,\n",
    "'Golden Gate Park':7,\n",
    "'Lincoln Park':7,\n",
    "'Presidio':7,\n",
    "'Marina':4,\n",
    "'Pacific Heights':4,\n",
    "'Japantown':4,\n",
    "'Presidio Heights':5,\n",
    "'Lone Mountain/USF':5,\n",
    "'Western Addition':5,\n",
    "'Haight Ashbury':5,\n",
    "'Hayes Valley':5,\n",
    "'Tenderloin':2,\n",
    "'South of Market':2,\n",
    "'North Beach':1,\n",
    "'Chinatown':1,\n",
    "'Russian Hill':1,\n",
    "'Nob Hill':1,\n",
    "'Financial District/South Beach':3,\n",
    "'Mission Bay':3,\n",
    "'Treasure Island':3,  \n",
    "'Castro/Upper Market':6,  # change this from 6 to 2 when you get the chance\n",
    "'Noe Valley':6,\n",
    "'Mission':6,\n",
    "'Bernal Heights':6,  \n",
    "'Glen Park':6,\n",
    "'Potrero Hill':10,\n",
    "'Bayview Hunters Point':10, \n",
    "'Oceanview/Merced/Ingleside':9,\n",
    "'Excelsior':9,\n",
    "'Visitacion Valley':9, \n",
    "'Portola':9,\n",
    "'Outer Mission':9,\n",
    "'McLaren Park':9,\n",
    "'West of Twin Peaks':9,                  \n",
    "'Sunset/Parkside':8,\n",
    "'Lakeshore':8,\n",
    "'Inner Sunset':8,\n",
    "'Twin Peaks':8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "# Creating a new column with new battalion labels\n",
    "amb_df['new_battalions'] = amb_df['Neighborhooods - Analysis Boundaries'].map(new_battalions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009090469460532528"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of rows without a neighborhood label\n",
    "len(amb_df[amb_df['new_battalions'].isnull() == True])/len(amb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# Changing all null values to zeroes for next steps\n",
    "amb_df['new_battalions'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Relabeling 'None' neighborhood rows with New Battalion label\n",
    "def relabeling_batallion_nulls(row):\n",
    "    \n",
    "    battalion_10_addresses = ['TULARE ST/INDIANA ST',\n",
    "    '3300 Block of 3RD ST',\n",
    "    '3200 Block of 3RD ST',\n",
    "    'INDIANA ST/TULARE ST',\n",
    "    '1200 Block of TULARE ST']\n",
    "\n",
    "\n",
    "    battalion_3_addresses = ['4TH ST/CHANNEL ST',\n",
    "    'CHANNEL ST/4TH ST',\n",
    "    '3RD ST/CHANNEL ST',\n",
    "    '900 Block of 3RD ST',\n",
    "    'CHANNEL ST/3RD ST']\n",
    "    \n",
    "    # Creating index variables for columns\n",
    "    new_battalions_ix = amb_df.columns.get_loc('new_battalions')\n",
    "    address_ix = amb_df.columns.get_loc('Address')\n",
    "    \n",
    "    # Changing null values to correct battalion number\n",
    "    if not row[new_battalions_ix]  == 0:\n",
    "        if row[address_ix] in battalion_10_addresses: \n",
    "            return 10.0\n",
    "        elif row[address_ix] in battalion_3_addresses:\n",
    "            return 3.0\n",
    "        else:\n",
    "            return 9.0\n",
    "    else:\n",
    "        return row[new_battalions_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-93e2da44e5ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Replace all nulls with correct battalion number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mamb_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'new_battalions'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamb_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelabeling_batallion_nulls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6485\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6486\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;31m# Create a dummy Series from an empty array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5323\u001b[0m         \"\"\"\n\u001b[1;32m   5324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5327\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mas_array\u001b[0;34m(self, transpose, items)\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtranspose\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_interleave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m             \u001b[0mitemmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mget_values\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2078\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2080\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Replacing all nulls with correct battalion number\n",
    "amb_df.loc[:,'new_battalions'] = amb_df.apply(relabeling_batallion_nulls, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values after apply function - There are none!\n",
    "amb_df[amb_df['new_battalions'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing calls not in san fransisco or directly on the boundaries\n",
    "non_sf_locations = ['CALL BOX: 1 ANGEL ISLAND DR',\n",
    "'CALL BOX: INTERSTATE 80 EB/ALAMEDA COUN,SF',\n",
    "'CALL BOX: 1900 SULLIVAN AV,DC',\n",
    "'CALL BOX: SF INTERNATIONAL AIRPORT']\n",
    "print('Percentage of dropped values:',len(amb_df[amb_df.Address.isin(non_sf_locations)])/len(amb_df)*100,'%')\n",
    "\n",
    "amb_df = amb_df[amb_df.Address.isin(non_sf_locations) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating CSV after binning neighborhoods/assigning labels\n",
    "amb_df.to_csv('ambulance_battalions_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling the cleaned dataframe\n",
    "redo_pickle = False\n",
    "\n",
    "if redo_pickle == True:\n",
    "    with open('ambulance_battalion_clean.pickle','wb') as f:\n",
    "        pickle.dump(amb_df,f)\n",
    "        \n",
    "if redo_pickle == False:\n",
    "    with open('ambulance_battalion_clean.pickle','rb') as f:\n",
    "        amb_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA on New Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0     480666\n",
       "6.0     286012\n",
       "9.0     177157\n",
       "5.0     174519\n",
       "1.0     153004\n",
       "3.0     141613\n",
       "8.0     133545\n",
       "10.0    127593\n",
       "7.0      88676\n",
       "4.0      77309\n",
       "Name: new_battalions, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at distribution of calls for each battalion\n",
    "amb_df['new_battalions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values: 42327\n",
      "Percent Missing: 0.023002629213507597\n"
     ]
    }
   ],
   "source": [
    "# Number of null values for unavailable times in dataframe\n",
    "print('Null Values:',len(amb_df[amb_df['Unavailable_Time'].isnull()] == True))\n",
    "print('Percent Missing:',1 - (1797767/len(amb_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013    3556\n",
       "2002    3507\n",
       "2011    3371\n",
       "2012    3365\n",
       "2006    3068\n",
       "2010    3055\n",
       "2003    3049\n",
       "2001    2940\n",
       "2008    2936\n",
       "2007    2829\n",
       "2005    2610\n",
       "2004    2585\n",
       "2009    2575\n",
       "2000    1927\n",
       "2014     803\n",
       "2015      43\n",
       "2016      40\n",
       "2017      33\n",
       "2018      28\n",
       "2019       7\n",
       "Name: Call Date, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of years by number of missing unavailable times\n",
    "amb_df[amb_df['Unavailable_Time'].isnull()]['Call Date'].dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Time Series for Each Battalion\n",
    "- Initially, I tried 15 minute intervals but they made the data too sparse and had long computation times with time series models. \n",
    "- I chose **30 minute intervals** instead because they still were granular enough but weren't as sparse or computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335387"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thirty_min_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding total unavailable units every 30 minutes\n",
    "def df_to_30_min_time_series(df):\n",
    "    '''\n",
    "    Using input of a dataframe, returns a time series\n",
    "    of the number of ambulances currently on a call \n",
    "    every 30 minutes. \n",
    "    '''\n",
    "    thirty_min_intervals = pd.date_range(start='4/12/2000 21:00:00',\n",
    "                                         end='5/31/2019 02:00:00',freq='30min')\n",
    "    counts = defaultdict(int)\n",
    "    print('Starting')\n",
    "    for interval in thirty_min_intervals:\n",
    "        count = len(df[(interval > df['Dispatch DtTm']) & (interval < df['Available DtTm'])])\n",
    "        counts[interval] = count\n",
    "    print('Finished')\n",
    "    return pd.Series(data=counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataframe for Each Battalion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "battalion_1_df = amb_df[amb_df['new_battalions'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "battalion_2_df = amb_df[amb_df['new_battalions'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "battalion_3_df = amb_df[amb_df['new_battalions'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "battalion_4_df = amb_df[amb_df['new_battalions'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "battalion_5_df = amb_df[amb_df['new_battalions'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "battalion_6_df = amb_df[amb_df['new_battalions'] == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "battalion_7_df = amb_df[amb_df['new_battalions'] == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "battalion_8_df = amb_df[amb_df['new_battalions'] == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "battalion_9_df = amb_df[amb_df['new_battalions'] == 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "battalion_10_df = amb_df[amb_df['new_battalions'] == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of all battalions\n",
    "battalion_df_list = [battalion_1_df, battalion_2_df, battalion_3_df, \n",
    "                  battalion_4_df, battalion_5_df, battalion_6_df, \n",
    "                  battalion_7_df, battalion_8_df, battalion_9_df, \n",
    "                  battalion_10_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Finished\n",
      "Starting\n",
      "Finished\n",
      "Starting\n",
      "Finished\n",
      "Starting\n",
      "Finished\n",
      "Starting\n",
      "Finished\n",
      "Starting\n",
      "Finished\n",
      "Starting\n",
      "Finished\n",
      "Starting\n",
      "Finished\n",
      "Starting\n",
      "Finished\n",
      "Starting\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# Converting each battalion dataframe into a 30 minute interval time series\n",
    "# with counts for how may ambulances were currently being used\n",
    "battalion_time_series_list = []\n",
    "for battalion_df in battalion_df_list:\n",
    "    battalion_time_series = df_to_30_min_time_series(battalion_df)\n",
    "    battalion_time_series_list.append(battalion_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling all battalion time series\n",
    "redo_pickle = False\n",
    "\n",
    "if redo_pickle:\n",
    "    for num in range(10):\n",
    "        with open(f'bat_{num+1}_30_min.pickle','wb') as f:\n",
    "            pickle.dump(battalion_time_series_list[num],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
